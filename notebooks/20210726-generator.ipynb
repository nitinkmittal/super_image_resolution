{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62b79fe-d797-4536-bb1b-d9388c38e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "626b02da-0fa5-40ec-8589-edf0fd2cdb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5eb280-ea16-475b-92cd-a2726e6bb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_image_resolution.modules.patch_discriminator import PatchDiscriminator\n",
    "from super_image_resolution.modules.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b52a7-6c32-4ccd-a3b7-ca08163881fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCGAN():\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int, \n",
    "        out_channels:int, \n",
    "        gen_norm: str, \n",
    "        gen_act: str, \n",
    "        gen_final_act: str, \n",
    "        dis_norm: str,\n",
    "        dis_act: str, \n",
    "        dis_final_act: str, \n",
    "        dis_depth: int, \n",
    "        dis_kernel_size: Union[int, Tuple[int, int]],\n",
    "        dis_stride: Union[int, Tuple[int, int]],\n",
    "        dis_padding:Union[int, Tuple[int, int]],\n",
    "        gen_loss_weight: float, \n",
    "        dis_loss_weight: float):\n",
    "        \n",
    "        self.gen = UNet(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels, \n",
    "            norm=self.gen_norm, \n",
    "            activation=self.gen_act, \n",
    "            final_act=self.gen_final_act)\n",
    "        \n",
    "        self.dis = PatchDiscriminator(\n",
    "            in_channels=self.out_channels, \n",
    "            depth=self.dis_depth, \n",
    "            dis_kernel_size=self.dis_depth, \n",
    "            stride=self.dis_stride,\n",
    "            padding=self.dis_padding, \n",
    "            activation=self.dis_act, \n",
    "            norm=self.dis_norm, \n",
    "            final_activation=self.dis_final_act)\n",
    "        \n",
    "        self.reconst_criterion = nn.L1Loss()\n",
    "        self.adv_criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        self.gen_loss_weight = gen_loss_weight\n",
    "        self.dis_loss_weight = dis_loss_weight\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.gen(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim_gen = torch.optim.Adam(self.gen.parameters(), lr=1e-3)\n",
    "        optim_dis = torch.optim.Adam(self.gen.parameters(), lr=1e-3)\n",
    "        return [optim_gen, optim_dis], []\n",
    "    \n",
    "    def generator_step(self, x: Tensor, y: Tensor, mode:str) -> torch.float:\n",
    "        y_hat = self.gen(x)\n",
    "        reconst_loss = self.gen_loss_weight * self.reconst_loss(y_hat, y)\n",
    "        \n",
    "        self.log(f\"gen_{mode}_reconst_loss\", reconst_loss.item())\n",
    "        \n",
    "        dis_hat_out = self.dis(y_hat)\n",
    "        adv_loss = self.dis_loss_weight * self.adv_criterion(\n",
    "            dis_hat_out, \n",
    "            torch.ones_like(self.dis_out, requires_grad=False).cuda())\n",
    "        \n",
    "        self.log(f\"gen_{mode}_adv_loss\", adv_loss.item(), on_step=True, sync_dist=True, prog_bar=True)\n",
    "        return reconst_loss + adv_loss\n",
    "    \n",
    "    def discriminator_step(self, x: Tensor, y: Tensor, mode: str) -> torch.float:\n",
    "        \n",
    "        y_hat = self.gen(x)\n",
    "        dis_hat_out = self.dis(y_hat.detach())\n",
    "        adv_hat_loss = self.dis_loss_weight * self.adv_criterion(\n",
    "            dis_hat_out, torch.zeros_like(dis_hat_out, requires_grad=False).cuda())\n",
    "        \n",
    "        dis_out = self.dis(y)\n",
    "        adv_loss = self.dis_loss_weight * self.adv_criterion(\n",
    "            dis_out,\n",
    "            torch.ones_like())\n",
    "        \n",
    "        dis_out\n",
    "        \n",
    "\tdef training_step(self, train_batch, batch_idx):\n",
    "\t\tx, y = train_batch\n",
    "\t\tx = x.view(x.size(0), -1)\n",
    "\t\tz = self.encoder(x)    \n",
    "\t\tx_hat = self.decoder(z)\n",
    "\t\tloss = F.mse_loss(x_hat, x)\n",
    "\t\tself.log('train_loss', loss)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, val_batch, batch_idx):\n",
    "\t\tx, y = val_batch\n",
    "\t\tx = x.view(x.size(0), -1)\n",
    "\t\tz = self.encoder(x)\n",
    "\t\tx_hat = self.decoder(z)\n",
    "\t\tloss = F.mse_loss(x_hat, x)\n",
    "\t\tself.log('val_loss', loss)\n",
    "\n",
    "# data\n",
    "dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=32)\n",
    "val_loader = DataLoader(mnist_val, batch_size=32)\n",
    "\n",
    "# model\n",
    "model = LitAutoEncoder()\n",
    "\n",
    "# training\n",
    "trainer = pl.Trainer(gpus=4, num_nodes=8, precision=16, limit_train_batches=0.5)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b05ca1a-7ecf-4403-8924-3ba2a311b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\tpip install pytorch-lightning\n",
    "  \n",
    "\tpip install pytorch-lightning\n",
    "  \n",
    "\tpip install pytorch-lightning\n",
    "  \n",
    "\tpip install pytorch-lightning\n",
    "  \n",
    "\tpip install pytorch-lightning\n",
    "  \n",
    "\tpip install pytorch-lightning\n",
    "  \n",
    "\tpip install pytorch-lightning\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f73729-4207-4866-8c3b-edde0776b684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae025efd-dc8e-48f9-b07e-d45a40e4c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = PatchDiscriminator(\n",
    "    in_channels=3,\n",
    "    depth=5,\n",
    "    kernel_size=4, \n",
    "    stride=2, \n",
    "    padding=1,\n",
    "    norm=\"batchnorm\", \n",
    "    activation=\"lrelu\", \n",
    "    final_activation=\"lrelu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529ff6b3-8f89-4acf-9094-d1de66b6a924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchDiscriminator(\n",
       "  (out): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (5): ModuleList(\n",
       "      (0): Conv2d(1024, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649e7001-3511-4c49-89a7-e2a728105822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis(torch.randn(1,3,256,256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8cf8dd-2987-4f34-a92f-fc21e24e319c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a42121-d656-4cbf-83c0-9d8bd5526c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_image_resolution",
   "language": "python",
   "name": "super_image_resolution"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
